/home/daniel/repos/github/Voice-Notepad

I've created a very nice utility for doing a transcription using cloud audio multimodal models, specifically using Gemini and the Gemini Flash 2.5 via OpenRouter, and I've provided a link above to the codebase. It's functional and working very well.

It does integrate this functionality, and I'm thinking it might make more sense to pull this out to its own utility, just to keep that tight and have its own. This might serve as a way to test that functionality independently.

The functionality I'm referring to is specifically the file-based transcription, in which instead of recording, providing the recording methodologies, allowing the user to upload one specific audio file to the Gemini API and receive a transcript. The basic functionality of the application involves, besides that, besides sending the audio for transcription, doing a little bit of pre-processing for the audio file based on VAD silence detection, compressing compression to make sure that it comes under the audio limit, converting stereo down to mono, degrading the bitrate a little bit. So basically, just preparing it for avoiding sending, because there's a limit for the file size the API can process. I'm doing a little bit of work before it even hits the API to make sure that it's well optimized for what it's going to be doing.

Then regarding the actual system prompts that get sent alongside the text, we have a general system prompt for providing an overall cleanup, removing filler words, adding punctuation and paragraphs. And then there are a couple of prompt layers on top of that that can be defined by the user. I'd like to replicate that kind of process in this app, that you can define the user can either add a custom system prompt that they write by hand in the app, or they use one of the existing templates. For the templates, I'd like to, by default, have the general cleanup system prompt applying or on, and then allow the other options to be added if desired. The ones that are very core and used all the time would be stuff like tech documentation, emails, and the other ones.

The other feature that's very useful and relevant in this regard, I think, is the personalization, by which you can add your name and email. That's very helpful because it's injected into the email template. If the user chooses that, in addition to their voice memo, the API gets their name and signature and is instructed to add that. So it's basically a prompt concatenation logic on the back end that provides audio with these instructions and then gets a transcript that's very targeted. It's using structured prompting so that in addition to the cleaned up transcript, the formatted transcript, it also generates a title. The idea there is that the user can download this as a file and that title can be used for the file name.

Like how the app works, it should be received as a box with the transcribed text, so that the user can make any light edits they wish before downloading it or copying it to the clipboard. Like in the app, if we send, if we start a new job, a new upload job, that can be considered like a new turn and clean out the existing transcription options. Of course, we need a setting place for the OpenRouter key that's persistent and stored locally on file and something that's saved on the user's local computer as well. So basically, it's a kind of a replicated version of the Voice Notepad app, but this one just doesn't have support for direct audio recording capture. It's only for file-based transcription where the user has a pre-recorded audio file, and it's doing the pre-processing logic as well as the transcript logic in order to generate a formatted transcript.